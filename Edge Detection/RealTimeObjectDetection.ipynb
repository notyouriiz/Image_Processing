{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Real-Time Object Measurement\n",
    "\n",
    "### âœ… If the Camera Never Moves\n",
    "If the **camera position, angle, focus, and distance stay the same**, then the measurement remains accurate **only if the new object is placed exactly where the calibrated object was**.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… When It **Will Still Be Accurate**\n",
    "* âœ”ï¸ Object is on the **same flat surface**\n",
    "* âœ”ï¸ Object is at the **same distance from the camera**\n",
    "* âœ”ï¸ Object is **not tilted** (same orientation as the remote)\n",
    "* âœ”ï¸ Camera does **not auto-zoom or change focal length**\n",
    "* âœ”ï¸ Lighting does not break contour detection\n",
    "\n",
    "ðŸ”¹ In this scenario, replacing the remote with an iPhone will still produce correct measurement.\n",
    "\n",
    "---\n",
    "\n",
    "### âŒ When It Becomes Inaccurate (Even if Camera Doesnâ€™t Move)\n",
    "| Issue                                 | Why it breaks                     |\n",
    "| ------------------------------------- | --------------------------------- |\n",
    "| Object is closer/farther from camera  | Pixel size changes                |\n",
    "| Object is tilted upward/downward      | Perspective distortion            |\n",
    "| Camera autofocus changes focal length | Scale becomes invalid             |\n",
    "| Different edge detection shape        | Bounding box changes              |\n",
    "| Object is thick or curved             | Detected contour is not true size |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Key Reminder\n",
    "Your current method uses **2D pixel-to-cm scaling** based on a **single object calibration**.\n",
    "It assumes the object lies on **the same plane (same Z-depth)**.\n",
    "\n",
    "```\n",
    "cm_per_pixel = real_size_cm / detected_pixel_size\n",
    "```\n",
    "\n",
    "If depth changes â†’ pixel size changes â†’ result becomes wrong.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Example\n",
    "| Object               | Distance | Pixel Height | Real Height | Result             |\n",
    "| -------------------- | -------- | ------------ | ----------- | ------------------ |\n",
    "| Remote (calibration) | 40 cm    | 250 px       | 16 cm       | âœ… Correct          |\n",
    "| iPhone in same spot  | 40 cm    | 400 px       | 14.7 cm     | âœ… Correct          |\n",
    "| iPhone moved closer  | 35 cm    | 450 px       | 14.7 cm     | âŒ Measured too big |\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Final Answer\n",
    "* âœ… If the new object is in **exact same position** â†’ measurement stays accurate.\n",
    "* âŒ If distance or angle changes even slightly â†’ measurement becomes inaccurate.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ›  Want Accuracy for Any Object, Any Distance?\n",
    "| Method                                   | Depth Safe? | Works for Any Object? |\n",
    "| ---------------------------------------- | ----------- | --------------------- |\n",
    "| Use reference object (coin, credit card) | âœ…           | âœ…                     |\n",
    "| Use ArUco marker                         | âœ…           | âœ…                     |\n",
    "| Stereo / depth camera                    | âœ…           | âœ…                     |\n",
    "| Full camera calibration                  | âœ…           | âœ…                     |\n",
    "| Your current single-object calibration   | âŒ           | âŒ                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Object Detection using Real-Life References Measured Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_21180\\2237712310.py:83: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    }
   ],
   "source": [
    "# === DISPLAY FUNCTION (unchanged) ===\n",
    "def display_comparison(original_img, edge_img, title1=\"Edge Detection\", title2=\"Detected Object\"):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    axs[0].imshow(cv2.cvtColor(edge_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(title1)\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[1].set_title(title2)\n",
    "    axs[1].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# SELECT IMAGE OR VIDEO (Real Time -> Webcam=True | Detect Video -> Webcam = False)\n",
    "use_webcam = False\n",
    "video_path = \"assets/video2.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(0 if use_webcam else video_path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Tidak bisa membuka video / webcam.\")\n",
    "\n",
    "\n",
    "# REAL SIZE REFERENCE (cm)\n",
    "actual_width_cm = 4.0\n",
    "actual_height_cm = 4.0\n",
    "\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = img.copy()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # === 1) OBJECT MASK (bright region only) ===\n",
    "    _, obj_mask = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # === 2) LOCAL BRIGHTNESS / CONTRAST FIX (only inside detected bright object) ===\n",
    "    edited = frame.astype(np.float32)\n",
    "    edited += 100          # brightness +100\n",
    "    edited = edited * 0.5 + 64   # reduce contrast\n",
    "    edited = np.clip(edited, 0, 255).astype(np.uint8)\n",
    "\n",
    "    edited_obj = frame.copy()\n",
    "    edited_obj[obj_mask == 255] = edited[obj_mask == 255]\n",
    "\n",
    "    # === 3) EDGE DETECTION PIPELINE (like your improved image version) ===\n",
    "    gray2 = cv2.cvtColor(edited_obj, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray2, (9, 9), 0)\n",
    "    sobel_x = cv2.Sobel(blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel = cv2.magnitude(sobel_x, sobel_y)\n",
    "    sobel = cv2.convertScaleAbs(sobel)\n",
    "    _, thresh = cv2.threshold(sobel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    thresh_closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # === 4) FIND LARGEST CONTOUR ===\n",
    "    contours, _ = cv2.findContours(thresh_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        largest = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # âœ… ROTATED RECTANGLE (accurate even if object rotates)\n",
    "        rect = cv2.minAreaRect(largest)\n",
    "        (cx, cy), (w_rot, h_rot), angle = rect\n",
    "\n",
    "        detected_width_px = min(w_rot, h_rot)\n",
    "        detected_height_px = max(w_rot, h_rot)\n",
    "\n",
    "        # âœ… Accurate cm-per-pixel\n",
    "        cm_per_pixel_w = actual_width_cm / detected_width_px\n",
    "        cm_per_pixel_h = actual_height_cm / detected_height_px\n",
    "        cm_per_pixel_avg = (cm_per_pixel_w + cm_per_pixel_h) / 2\n",
    "\n",
    "        object_width_cm = detected_width_px * cm_per_pixel_avg\n",
    "        object_height_cm = detected_height_px * cm_per_pixel_avg\n",
    "\n",
    "        # Draw bounding box\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(frame, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(frame, f\"Width: {object_width_cm:.2f} cm\",\n",
    "                    (box[0][0], box[0][1] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(frame, f\"Height: {object_height_cm:.2f} cm\",\n",
    "                    (box[0][0], box[0][1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Robust Object Measurement (Video)\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Measurement using ArUco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import cv2.aruco as aruco\n",
    "import math\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import cv2, cv2.aruco as aruco\n",
    "print(cv2.__version__)\n",
    "print(hasattr(aruco, \"detectMarkers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings (change source if needed)\n",
    "use_webcam = True\n",
    "video_path = \"assets/video1.mov\"  # used if use_webcam == False\n",
    "\n",
    "# Marker config (lowercase variable name as requested)\n",
    "marker_size_mm = 50  # mm (50 mm -> 5.0 cm)\n",
    "target_marker_id = 0\n",
    "dict_choice = aruco.DICT_4X4_50\n",
    "\n",
    "# Behavior\n",
    "mode_soft = True  # if True: use last known scale when marker lost\n",
    "min_contour_area = 200  # filter out tiny noise contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_distance(p1: Tuple[float, float], p2: Tuple[float, float]) -> float:\n",
    "    \"\"\"Return Euclidean distance between two 2D points.\"\"\"\n",
    "    return math.hypot(p1[0] - p2[0], p1[1] - p2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_aruco_scale(\n",
    "    gray_frame: np.ndarray,\n",
    "    aruco_detector: aruco.ArucoDetector,\n",
    "    target_id: int,\n",
    "    marker_size_cm: float,\n",
    ") -> Tuple[Optional[float], Optional[float], Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Detect target ArUco marker and compute cm-per-pixel scale.\n",
    "\n",
    "    Args:\n",
    "        gray_frame: Grayscale image.\n",
    "        aruco_detector: OpenCV ArucoDetector instance.\n",
    "        target_id: marker id to look for (e.g. 0).\n",
    "        marker_size_cm: real-world side length of marker in centimeters.\n",
    "\n",
    "    Returns:\n",
    "        (cm_per_pixel, measured_marker_cm, corners_array)\n",
    "        - cm_per_pixel: float or None if not detected\n",
    "        - measured_marker_cm: measured marker side length in cm (debug), or None\n",
    "        - corners_array: np.ndarray of 4x2 corner points for the found marker (or None)\n",
    "    \"\"\"\n",
    "    corners, ids, _ = aruco_detector.detectMarkers(gray_frame)\n",
    "\n",
    "    if ids is None or len(corners) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    ids_flat = ids.flatten()\n",
    "    if target_id not in ids_flat:\n",
    "        return None, None, None\n",
    "\n",
    "    idx = int(np.where(ids_flat == target_id)[0][0])\n",
    "    c = corners[idx].reshape((4, 2))\n",
    "\n",
    "    # compute average side length in pixels (top + right) / 2\n",
    "    top = pixel_distance(c[0], c[1])\n",
    "    right = pixel_distance(c[1], c[2])\n",
    "    marker_px = (top + right) / 2.0\n",
    "\n",
    "    if marker_px <= 0:\n",
    "        return None, None, None\n",
    "\n",
    "    cm_per_pixel = marker_size_cm / marker_px\n",
    "    measured_marker_cm = marker_px * cm_per_pixel  # should equal marker_size_cm (debug)\n",
    "\n",
    "    return cm_per_pixel, measured_marker_cm, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_largest_object(gray_frame: np.ndarray) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Detect the largest contour (object) using a Sobel-based pipeline.\n",
    "    Returns the largest contour or None if not found.\n",
    "    \"\"\"\n",
    "    blur = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "    sobel_x = cv2.Sobel(blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel = cv2.magnitude(sobel_x, sobel_y)\n",
    "    sobel = cv2.convertScaleAbs(sobel)\n",
    "\n",
    "    _, thresh = cv2.threshold(sobel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    thresh_closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    if cv2.contourArea(largest) < min_contour_area:\n",
    "        return None\n",
    "    return largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_from_rect(rect: Tuple) -> Tuple[float, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Given a minAreaRect result, return (w_px, h_px, box_points)\n",
    "    where w_px is the smaller side (width) and h_px the larger (height).\n",
    "    \"\"\"\n",
    "    (cx, cy), (w_rot, h_rot), angle = rect\n",
    "    w_px = min(w_rot, h_rot)\n",
    "    h_px = max(w_rot, h_rot)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    return w_px, h_px, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_21180\\606261165.py:10: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_21180\\2252595375.py:50: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  int_box = np.int0(marker_corners)\n"
     ]
    }
   ],
   "source": [
    "def run_measurement(\n",
    "    source_is_webcam: bool = True,\n",
    "    video_path_local: str = \"assets/video3\",\n",
    "    marker_size_mm_local: int = 50,\n",
    "    marker_id_local: int = 0,\n",
    "    dict_choice_local=aruco.DICT_4X4_50,\n",
    "    soft_mode: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main loop: open capture, detect ArUco, detect object, measure, and display.\n",
    "\n",
    "    Args:\n",
    "        source_is_webcam: True to use webcam (0); False to use video_path_local.\n",
    "        video_path_local: path to video file if not using webcam.\n",
    "        marker_size_mm_local: marker physical size in millimeters.\n",
    "        marker_id_local: ArUco ID to detect.\n",
    "        dict_choice_local: ArUco dictionary constant.\n",
    "        soft_mode: if True, reuse last known scale when marker missing.\n",
    "    \"\"\"\n",
    "    marker_size_cm_local = marker_size_mm_local / 10.0\n",
    "\n",
    "    # Open capture\n",
    "    cap = cv2.VideoCapture(0 if source_is_webcam else video_path_local)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam or video file.\")\n",
    "\n",
    "    # Create ArUco detector (new API)\n",
    "    aruco_dict_local = aruco.getPredefinedDictionary(dict_choice_local)\n",
    "    parameters = aruco.DetectorParameters()\n",
    "    aruco_detector = aruco.ArucoDetector(aruco_dict_local, parameters)\n",
    "\n",
    "    last_cm_per_pixel_local: Optional[float] = None\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            vis = frame.copy()\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect ArUco and compute scale\n",
    "            cm_per_pixel, measured_marker_cm, marker_corners = detect_aruco_scale(\n",
    "                gray, aruco_detector, marker_id_local, marker_size_cm_local\n",
    "            )\n",
    "\n",
    "            # If detected, draw blue polygon and label; else fallback\n",
    "            if marker_corners is not None:\n",
    "                int_box = np.int0(marker_corners)\n",
    "                cv2.polylines(vis, [int_box], True, (255, 0, 0), 3)  # blue box\n",
    "\n",
    "                # display both scale and measured marker size (option C)\n",
    "                cv2.putText(vis, f\"Scale: {cm_per_pixel:.6f} cm/px\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 0), 2)\n",
    "                cv2.putText(vis, f\"Marker size (meas): {measured_marker_cm:.2f} cm\",\n",
    "                            (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 0), 2)\n",
    "\n",
    "                last_cm_per_pixel_local = cm_per_pixel\n",
    "                marker_status_text = f\"Marker OK (ID {marker_id_local})\"\n",
    "            else:\n",
    "                if last_cm_per_pixel_local is not None and soft_mode:\n",
    "                    marker_status_text = \"Marker lost - using last scale\"\n",
    "                    cv2.putText(vis, f\"Scale (last): {last_cm_per_pixel_local:.6f} cm/px\",\n",
    "                                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 0), 2)\n",
    "                else:\n",
    "                    marker_status_text = \"No scale - pixel units only\"\n",
    "\n",
    "                # Optionally show that no marker was found\n",
    "                cv2.putText(vis, marker_status_text, (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "            # Detect largest object and measure\n",
    "            largest_contour = detect_largest_object(gray)\n",
    "            if largest_contour is not None:\n",
    "                rect = cv2.minAreaRect(largest_contour)\n",
    "                w_px, h_px, box = measure_from_rect(rect)\n",
    "\n",
    "                # Draw object bounding box (green)\n",
    "                cv2.drawContours(vis, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "                # Use detected or last-known scale to convert to cm\n",
    "                used_scale = None\n",
    "                if cm_per_pixel is not None:\n",
    "                    used_scale = cm_per_pixel\n",
    "                elif last_cm_per_pixel_local is not None and soft_mode:\n",
    "                    used_scale = last_cm_per_pixel_local\n",
    "\n",
    "                if used_scale is not None:\n",
    "                    w_cm = w_px * used_scale\n",
    "                    h_cm = h_px * used_scale\n",
    "                    cv2.putText(vis, f\"W: {w_cm:.2f} cm\", (box[0][0], box[0][1] - 15),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                    cv2.putText(vis, f\"H: {h_cm:.2f} cm\", (box[0][0], box[0][1] + 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    # show pixel fallback\n",
    "                    cv2.putText(vis, f\"W: {w_px:.1f} px\", (box[0][0], box[0][1] - 15),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "                    cv2.putText(vis, f\"H: {h_px:.1f} px\", (box[0][0], box[0][1] + 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "            else:\n",
    "                cv2.putText(vis, \"No object contours found\", (10, vis.shape[0] - 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "            # Status text near top-left (marker status)\n",
    "            cv2.putText(vis, marker_status_text, (10, 80),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 200, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"ArUco Measurement (function-based)\", vis)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # run using the global settings above\n",
    "    run_measurement(\n",
    "        source_is_webcam=use_webcam,\n",
    "        video_path_local=video_path,\n",
    "        marker_size_mm_local=marker_size_mm,\n",
    "        marker_id_local=target_marker_id,\n",
    "        dict_choice_local=dict_choice,\n",
    "        soft_mode=mode_soft,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
