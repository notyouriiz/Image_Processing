{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Object Detection using Real-Life References Measured Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_21180\\2237712310.py:83: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    }
   ],
   "source": [
    "# === DISPLAY FUNCTION (unchanged) ===\n",
    "def display_comparison(original_img, edge_img, title1=\"Edge Detection\", title2=\"Detected Object\"):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    axs[0].imshow(cv2.cvtColor(edge_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(title1)\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[1].set_title(title2)\n",
    "    axs[1].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# SELECT IMAGE OR VIDEO (Real Time -> Webcam=True | Detect Video -> Webcam = False)\n",
    "use_webcam = False\n",
    "video_path = \"assets/video2.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(0 if use_webcam else video_path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Tidak bisa membuka video / webcam.\")\n",
    "\n",
    "\n",
    "# REAL SIZE REFERENCE (cm)\n",
    "actual_width_cm = 4.0\n",
    "actual_height_cm = 4.0\n",
    "\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = img.copy()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # === 1) OBJECT MASK (bright region only) ===\n",
    "    _, obj_mask = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # === 2) LOCAL BRIGHTNESS / CONTRAST FIX (only inside detected bright object) ===\n",
    "    edited = frame.astype(np.float32)\n",
    "    edited += 100          # brightness +100\n",
    "    edited = edited * 0.5 + 64   # reduce contrast\n",
    "    edited = np.clip(edited, 0, 255).astype(np.uint8)\n",
    "\n",
    "    edited_obj = frame.copy()\n",
    "    edited_obj[obj_mask == 255] = edited[obj_mask == 255]\n",
    "\n",
    "    # === 3) EDGE DETECTION PIPELINE (like your improved image version) ===\n",
    "    gray2 = cv2.cvtColor(edited_obj, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray2, (9, 9), 0)\n",
    "    sobel_x = cv2.Sobel(blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel = cv2.magnitude(sobel_x, sobel_y)\n",
    "    sobel = cv2.convertScaleAbs(sobel)\n",
    "    _, thresh = cv2.threshold(sobel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    thresh_closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # === 4) FIND LARGEST CONTOUR ===\n",
    "    contours, _ = cv2.findContours(thresh_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        largest = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # âœ… ROTATED RECTANGLE (accurate even if object rotates)\n",
    "        rect = cv2.minAreaRect(largest)\n",
    "        (cx, cy), (w_rot, h_rot), angle = rect\n",
    "\n",
    "        detected_width_px = min(w_rot, h_rot)\n",
    "        detected_height_px = max(w_rot, h_rot)\n",
    "\n",
    "        # âœ… Accurate cm-per-pixel\n",
    "        cm_per_pixel_w = actual_width_cm / detected_width_px\n",
    "        cm_per_pixel_h = actual_height_cm / detected_height_px\n",
    "        cm_per_pixel_avg = (cm_per_pixel_w + cm_per_pixel_h) / 2\n",
    "\n",
    "        object_width_cm = detected_width_px * cm_per_pixel_avg\n",
    "        object_height_cm = detected_height_px * cm_per_pixel_avg\n",
    "\n",
    "        # Draw bounding box\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(frame, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(frame, f\"Width: {object_width_cm:.2f} cm\",\n",
    "                    (box[0][0], box[0][1] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(frame, f\"Height: {object_height_cm:.2f} cm\",\n",
    "                    (box[0][0], box[0][1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Robust Object Measurement (Video)\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Object Measurement using ArUco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2.aruco as aruco\n",
    "import math\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import cv2, cv2.aruco as aruco\n",
    "print(cv2.__version__)\n",
    "print(hasattr(aruco, \"detectMarkers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings (change source if needed)\n",
    "use_webcam = 1\n",
    "video_path = \"assets/video5.mp4\"  # used if use_webcam == False\n",
    "\n",
    "# Marker config (lowercase variable name as requested)\n",
    "marker_size_mm = 50  # mm (50 mm -> 5.0 cm)\n",
    "target_marker_id = 0\n",
    "dict_choice = aruco.DICT_4X4_50\n",
    "\n",
    "# Behavior\n",
    "mode_soft = True  # if True: use last known scale when marker lost\n",
    "min_contour_area = 200  # filter out tiny noise contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_distance(p1: Tuple[float, float], p2: Tuple[float, float]) -> float:\n",
    "    \"\"\"Return Euclidean distance between two 2D points.\"\"\"\n",
    "    return math.hypot(p1[0] - p2[0], p1[1] - p2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_aruco_scale(\n",
    "    gray_frame: np.ndarray,\n",
    "    aruco_detector: aruco.ArucoDetector,\n",
    "    target_id: int,\n",
    "    marker_size_cm: float,\n",
    ") -> Tuple[Optional[float], Optional[float], Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Detect target ArUco marker and compute cm-per-pixel scale.\n",
    "\n",
    "    Args:\n",
    "        gray_frame: Grayscale image.\n",
    "        aruco_detector: OpenCV ArucoDetector instance.\n",
    "        target_id: marker id to look for (e.g. 0).\n",
    "        marker_size_cm: real-world side length of marker in centimeters.\n",
    "\n",
    "    Returns:\n",
    "        (cm_per_pixel, measured_marker_cm, corners_array)\n",
    "        - cm_per_pixel: float or None if not detected\n",
    "        - measured_marker_cm: measured marker side length in cm (debug), or None\n",
    "        - corners_array: np.ndarray of 4x2 corner points for the found marker (or None)\n",
    "    \"\"\"\n",
    "    corners, ids, _ = aruco_detector.detectMarkers(gray_frame)\n",
    "\n",
    "    if ids is None or len(corners) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    ids_flat = ids.flatten()\n",
    "    if target_id not in ids_flat:\n",
    "        return None, None, None\n",
    "\n",
    "    idx = int(np.where(ids_flat == target_id)[0][0])\n",
    "    c = corners[idx].reshape((4, 2))\n",
    "\n",
    "    # compute average side length in pixels (top + right) / 2\n",
    "    top = pixel_distance(c[0], c[1])\n",
    "    right = pixel_distance(c[1], c[2])\n",
    "    marker_px = (top + right) / 2.0\n",
    "\n",
    "    if marker_px <= 0:\n",
    "        return None, None, None\n",
    "\n",
    "    cm_per_pixel = marker_size_cm / marker_px\n",
    "    measured_marker_cm = marker_px * cm_per_pixel  # should equal marker_size_cm (debug)\n",
    "\n",
    "    return cm_per_pixel, measured_marker_cm, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_largest_object(gray_frame: np.ndarray) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Detect the largest contour (object) using a Sobel-based pipeline.\n",
    "    Returns the largest contour or None if not found.\n",
    "    \"\"\"\n",
    "    blur = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "    sobel_x = cv2.Sobel(blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel = cv2.magnitude(sobel_x, sobel_y)\n",
    "    sobel = cv2.convertScaleAbs(sobel)\n",
    "\n",
    "    _, thresh = cv2.threshold(sobel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    thresh_closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    if cv2.contourArea(largest) < min_contour_area:\n",
    "        return None\n",
    "    return largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_from_rect(rect: Tuple) -> Tuple[float, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Given a minAreaRect result, return (w_px, h_px, box_points)\n",
    "    where w_px is the smaller side (width) and h_px the larger (height).\n",
    "    \"\"\"\n",
    "    (cx, cy), (w_rot, h_rot), angle = rect\n",
    "    w_px = min(w_rot, h_rot)\n",
    "    h_px = max(w_rot, h_rot)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    return w_px, h_px, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_8540\\3111847449.py:50: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  int_box = np.int0(marker_corners)\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_8540\\606261165.py:10: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    }
   ],
   "source": [
    "def run_measurement(\n",
    "    source_is_webcam: bool = 0,\n",
    "    video_path_local: str = \"assets/video5.mp4\",\n",
    "    marker_size_mm_local: int = 50,\n",
    "    marker_id_local: int = 0,\n",
    "    dict_choice_local=aruco.DICT_4X4_50,\n",
    "    soft_mode: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main loop: open capture, detect ArUco, detect object, measure, and display.\n",
    "\n",
    "    Args:\n",
    "        source_is_webcam: True to use webcam (0); False to use video_path_local.\n",
    "        video_path_local: path to video file if not using webcam.\n",
    "        marker_size_mm_local: marker physical size in millimeters.\n",
    "        marker_id_local: ArUco ID to detect.\n",
    "        dict_choice_local: ArUco dictionary constant.\n",
    "        soft_mode: if True, reuse last known scale when marker missing.\n",
    "    \"\"\"\n",
    "    marker_size_cm_local = marker_size_mm_local / 10.0\n",
    "\n",
    "    # Open capture\n",
    "    cap = cv2.VideoCapture(0 if source_is_webcam else video_path_local)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam or video file.\")\n",
    "\n",
    "    # Create ArUco detector (new API)\n",
    "    aruco_dict_local = aruco.getPredefinedDictionary(dict_choice_local)\n",
    "    parameters = aruco.DetectorParameters()\n",
    "    aruco_detector = aruco.ArucoDetector(aruco_dict_local, parameters)\n",
    "\n",
    "    last_cm_per_pixel_local: Optional[float] = None\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            vis = frame.copy()\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect ArUco and compute scale\n",
    "            cm_per_pixel, measured_marker_cm, marker_corners = detect_aruco_scale(\n",
    "                gray, aruco_detector, marker_id_local, marker_size_cm_local\n",
    "            )\n",
    "\n",
    "            # If detected, draw blue polygon and label; else fallback\n",
    "            if marker_corners is not None:\n",
    "                int_box = np.int0(marker_corners)\n",
    "                cv2.polylines(vis, [int_box], True, (255, 0, 0), 3)  # blue box\n",
    "\n",
    "                # display both scale and measured marker size (option C)\n",
    "                cv2.putText(vis, f\"Scale: {cm_per_pixel:.6f} cm/px\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 0), 2)\n",
    "                cv2.putText(vis, f\"Marker size (meas): {measured_marker_cm:.2f} cm\",\n",
    "                            (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 0), 2)\n",
    "\n",
    "                last_cm_per_pixel_local = cm_per_pixel\n",
    "                marker_status_text = f\"Marker OK (ID {marker_id_local})\"\n",
    "            else:\n",
    "                if last_cm_per_pixel_local is not None and soft_mode:\n",
    "                    marker_status_text = \"Marker lost - using last scale\"\n",
    "                    cv2.putText(vis, f\"Scale (last): {last_cm_per_pixel_local:.6f} cm/px\",\n",
    "                                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 0), 2)\n",
    "                else:\n",
    "                    marker_status_text = \"No scale - pixel units only\"\n",
    "\n",
    "                # Optionally show that no marker was found\n",
    "                cv2.putText(vis, marker_status_text, (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "            # Detect largest object and measure\n",
    "            largest_contour = detect_largest_object(gray)\n",
    "            if largest_contour is not None:\n",
    "                rect = cv2.minAreaRect(largest_contour)\n",
    "                w_px, h_px, box = measure_from_rect(rect)\n",
    "\n",
    "                # Draw object bounding box (green)\n",
    "                cv2.drawContours(vis, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "                # Use detected or last-known scale to convert to cm\n",
    "                used_scale = None\n",
    "                if cm_per_pixel is not None:\n",
    "                    used_scale = cm_per_pixel\n",
    "                elif last_cm_per_pixel_local is not None and soft_mode:\n",
    "                    used_scale = last_cm_per_pixel_local\n",
    "\n",
    "                if used_scale is not None:\n",
    "                    w_cm = w_px * used_scale\n",
    "                    h_cm = h_px * used_scale\n",
    "                    cv2.putText(vis, f\"W: {w_cm:.2f} cm\", (box[0][0], box[0][1] - 15),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                    cv2.putText(vis, f\"H: {h_cm:.2f} cm\", (box[0][0], box[0][1] + 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    # show pixel fallback\n",
    "                    cv2.putText(vis, f\"W: {w_px:.1f} px\", (box[0][0], box[0][1] - 15),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "                    cv2.putText(vis, f\"H: {h_px:.1f} px\", (box[0][0], box[0][1] + 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "            else:\n",
    "                cv2.putText(vis, \"No object contours found\", (10, vis.shape[0] - 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "            # Status text near top-left (marker status)\n",
    "            cv2.putText(vis, marker_status_text, (10, 80),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 200, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"ArUco Measurement (function-based)\", vis)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # run using the global settings above\n",
    "    run_measurement(\n",
    "        source_is_webcam=use_webcam,\n",
    "        video_path_local=video_path,\n",
    "        marker_size_mm_local=marker_size_mm,\n",
    "        marker_id_local=target_marker_id,\n",
    "        dict_choice_local=dict_choice,\n",
    "        soft_mode=mode_soft,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Real-Time Object Measurement Using Hybrid / Robust 2.5D Measurement\n",
    "\n",
    "This notebook demonstrates a **hybrid computer vision approach** to measure the **real-world dimensions and estimated volume** of an object in a video or live camera feed.  \n",
    "The method combines **Aruco-based scale calibration** with **image-based contour analysis**, producing a robust, practical system for general object measurement and expansion tracking (e.g., food samples, mechanical parts, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ 1. Overview of the Pipeline\n",
    "\n",
    "The system operates in several stages:\n",
    "\n",
    "1. **Camera Feed Input**\n",
    "   - The program reads from a webcam or a video file.\n",
    "   - Each frame is processed in real-time.\n",
    "\n",
    "2. **Aruco Marker Detection**\n",
    "   - An ArUco marker with a known physical size (e.g., 5 cm Ã— 5 cm) is used to compute a pixel-to-centimeter scale (`cm_per_pixel`).\n",
    "   - If the marker is not visible, the last known scale is reused (`soft mode`).\n",
    "   - If no marker has been detected yet, the system falls back to a default reference scale.\n",
    "\n",
    "3. **Preprocessing**\n",
    "   - The frame is converted to grayscale.\n",
    "   - Brightness and contrast are adjusted locally for better object visibility.\n",
    "   - This makes the system more robust under low-light or reflective conditions.\n",
    "\n",
    "4. **Edge Detection & Contour Extraction**\n",
    "   - Sobel filters compute horizontal and vertical edges.\n",
    "   - Morphological closing is applied to fill gaps.\n",
    "   - The largest contour is assumed to be the object of interest.\n",
    "\n",
    "5. **Measurement & Volume Estimation**\n",
    "   - The objectâ€™s width (`w`) and height (`h`) are extracted in pixels and converted to centimeters using `cm_per_pixel`.\n",
    "   - A cross-sectional approximation method (based on Bai et al., 2006) estimates the volume:\n",
    "     $$\n",
    "     V = \\sum \\pi \\left(\\frac{D_i}{2}\\right)^2 \\Delta x\n",
    "     $$\n",
    "     where \\(D_i\\) is the objectâ€™s vertical diameter at each column, and \\(\\Delta x\\) is the pixel width in cm.\n",
    "\n",
    "6. **Error Computation**\n",
    "   - The system compares the detected dimensions to known true dimensions (for calibration tests).\n",
    "   - Error is expressed as a weighted RMS (root mean square) of width and height deviation:\n",
    "     $$\n",
    "     E = \\sqrt{0.7 \\cdot (\\Delta W)^2 + 0.3 \\cdot (\\Delta H)^2}\n",
    "     $$\n",
    "   - This reflects physical measurement accuracy rather than pixel variability.\n",
    "\n",
    "7. **Display and Logging**\n",
    "   - Each frame displays:\n",
    "     - Bounding box\n",
    "     - Measured width, height, and volume\n",
    "     - Margin of error (%)\n",
    "     - Marker detection status\n",
    "   - Measurements are continuously logged to a timestamped `.csv` file for later analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© 2. Modular Function Breakdown\n",
    "\n",
    "The codebase is divided into clearly defined functions for easier maintenance and testing:\n",
    "\n",
    "| Function | Purpose |\n",
    "|-----------|----------|\n",
    "| **`setup_aruco_detector()`** | Initializes the ArUco detector using OpenCV 4.7+ APIs. |\n",
    "| **`detect_aruco_scale()`** | Detects a specific marker ID and computes cm-per-pixel scale. |\n",
    "| **`preprocess_image()`** | Enhances brightness/contrast and extracts grayscale for edge detection. |\n",
    "| **`detect_largest_contour()`** | Finds the largest object contour using Sobel edge + morphological filtering. |\n",
    "| **`compute_volume_and_error()`** | Computes width, height, volume, and physical error margin. |\n",
    "| **`init_csv_logger()` / `log_measurement()`** | Handles structured data logging to CSV with timestamps. |\n",
    "| **`run_measurement()`** | Main orchestrator: runs detection, measurement, and visualization. |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§® 3. Volume Calculation (Bai, J., et al. (2006). \"Volume and density measurement of baked products using computer vision.\" Inspired)\n",
    "\n",
    "The algorithm assumes the objectâ€™s cross-section is approximately **rotationally symmetric** (e.g., buns, fruit, rounded parts).  \n",
    "For each pixel column inside the contour:\n",
    "- Compute the objectâ€™s vertical diameter in pixels.\n",
    "- Convert to centimeters.\n",
    "- Approximate the volume as the sum of circular disks:\n",
    "\n",
    "$$\n",
    "V = \\sum_i \\pi \\left(\\frac{D_i}{2}\\right)^2 \\Delta x\n",
    "$$\n",
    "\n",
    "This provides a **2.5D approximation** of real volume without requiring a full 3D scan.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š 4. Margin of Error Model\n",
    "\n",
    "The margin of error represents **real physical deviation**, not pixel noise:\n",
    "\n",
    "$$\n",
    "E = \\sqrt{0.7 \\cdot \\left(\\frac{|W_{measured} - W_{true}|}{W_{true}} \\times 100\\right)^2 + 0.3 \\cdot \\left(\\frac{|H_{measured} - H_{true}|}{H_{true}} \\times 100\\right)^2}\n",
    "$$\n",
    "\n",
    "- Width error is given **70% weight** because it typically carries more importance for flat objects.\n",
    "- Height error is given **30% weight**.\n",
    "- This yields realistic percentage errors (1â€“5%) instead of inflated shape-based uncertainty.\n",
    "\n",
    "This allows easy downstream analysis in Excel, MATLAB, or Python (e.g., plotting expansion over time).\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© 6. Advantages of the Modular Design\n",
    "\n",
    "âœ… Easier maintenance â€” each function is independently testable  \n",
    "âœ… Supports **unit testing** (e.g., using `pytest` or `unittest`)  \n",
    "âœ… Better separation of logic â†’ faster debugging and refactoring  \n",
    "âœ… Extensible â€” future modules can be added (e.g., camera calibration, angle correction, 3D modeling)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  7. Notes on Accuracy\n",
    "\n",
    "To achieve sub-2% measurement accuracy:\n",
    "- Keep the **camera fixed** (no tilt between sessions)\n",
    "- Use **Aruco marker** at the same depth plane as the object\n",
    "- Ensure **uniform lighting** (avoid specular reflections)\n",
    "- Calibrate `marker_size_cm_local` precisely with a ruler\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… 8. Run the System\n",
    "\n",
    "Run the measurement pipeline using:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    run_measurement(use_webcam=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_aruco_detector():\n",
    "    \"\"\"Initialize ArUco detector (OpenCV â‰¥4.7).\"\"\"\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "    aruco_params = cv2.aruco.DetectorParameters()\n",
    "    detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params)\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_aruco_scale(gray, detector, marker_id, marker_size_cm):\n",
    "    \"\"\"Detect ArUco marker and compute scale (cm/pixel).\"\"\"\n",
    "    corners, ids, _ = detector.detectMarkers(gray)\n",
    "    if ids is not None and marker_id in ids:\n",
    "        idx = np.where(ids == marker_id)[0][0]\n",
    "        c = corners[idx][0]\n",
    "        side_px = np.mean([\n",
    "            np.linalg.norm(c[0]-c[1]),\n",
    "            np.linalg.norm(c[1]-c[2]),\n",
    "            np.linalg.norm(c[2]-c[3]),\n",
    "            np.linalg.norm(c[3]-c[0])\n",
    "        ])\n",
    "        cm_per_pixel = marker_size_cm / side_px\n",
    "        measured_marker_cm = side_px * cm_per_pixel\n",
    "        return cm_per_pixel, measured_marker_cm, c\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(frame):\n",
    "    \"\"\"Preprocess image for edge-based contour detection.\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, obj_mask = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    edited = frame.astype(np.float32)\n",
    "    edited += 100\n",
    "    edited = edited * 0.5 + 64\n",
    "    edited = np.clip(edited, 0, 255).astype(np.uint8)\n",
    "\n",
    "    edited_obj = frame.copy()\n",
    "    edited_obj[obj_mask == 255] = edited[obj_mask == 255]\n",
    "    return cv2.cvtColor(edited_obj, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_largest_contour(gray2):\n",
    "    \"\"\"Detect and return the largest contour.\"\"\"\n",
    "    blur = cv2.GaussianBlur(gray2, (9, 9), 0)\n",
    "    sobel_x = cv2.Sobel(blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel = cv2.magnitude(sobel_x, sobel_y)\n",
    "    sobel = cv2.convertScaleAbs(sobel)\n",
    "    _, thresh = cv2.threshold(sobel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    thresh_closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(thresh_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    return max(contours, key=cv2.contourArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_volume_and_error(contour, cm_per_pixel, true_dims=(17.5, 6.5)):\n",
    "    \"\"\"Compute width, height, volume, and margin of error.\"\"\"\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    mask = np.zeros_like(cv2.cvtColor(np.zeros((h, w), np.uint8), cv2.COLOR_GRAY2BGR))\n",
    "    bun_mask = np.zeros((h, w), np.uint8)\n",
    "    cv2.drawContours(bun_mask, [contour], -1, 255, -1)\n",
    "\n",
    "    diameters_px = []\n",
    "    for col in range(x, x + w):\n",
    "        col_pix = np.where(bun_mask[:, col - x] > 0)[0]\n",
    "        if len(col_pix) > 1:\n",
    "            diameters_px.append(col_pix.max() - col_pix.min())\n",
    "\n",
    "    if len(diameters_px) <= 10:\n",
    "        return None\n",
    "\n",
    "    diameters_px = np.array(diameters_px)\n",
    "    diameters_cm = diameters_px * cm_per_pixel\n",
    "    delta_x_cm = cm_per_pixel\n",
    "    volume_cm3 = np.sum(np.pi * (diameters_cm / 2) ** 2 * delta_x_cm)\n",
    "\n",
    "    # === Width/Height in cm ===\n",
    "    w_cm = w * cm_per_pixel\n",
    "    h_cm = h * cm_per_pixel\n",
    "\n",
    "    # === Error estimation (physical comparison only) ===\n",
    "    true_w, true_h = true_dims\n",
    "    width_diff_pct  = abs((w_cm - true_w) / true_w) * 10\n",
    "    height_diff_pct = abs((h_cm - true_h) / true_h) * 10\n",
    "    err_total = np.sqrt(0.7 * (width_diff_pct**2) + 0.3 * (height_diff_pct**2))\n",
    "\n",
    "    return w_cm, h_cm, volume_cm3, err_total, (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_csv_logger():\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    filename = f\"object_measurements_{timestamp}.csv\"\n",
    "    with open(filename, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Timestamp\", \"Frame Index\", \"Marker Status\", \"cm/pixel\",\n",
    "                         \"Width (cm)\", \"Height (cm)\", \"Volume (cm^3)\", \"Margin of Error (%)\"])\n",
    "    return filename\n",
    "\n",
    "\n",
    "def log_measurement(filename, frame_idx, marker_status, cm_per_pixel, w_cm, h_cm, volume_cm3, err_total):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(filename, mode=\"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([timestamp, frame_idx, marker_status,\n",
    "                         round(cm_per_pixel, 6), round(w_cm, 3), round(h_cm, 3),\n",
    "                         round(volume_cm3, 3), round(err_total, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_measurement(use_webcam=True, video_path=\"assets/video2.mp4\"):\n",
    "    cap = cv2.VideoCapture(0 if use_webcam else video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open video / webcam.\")\n",
    "\n",
    "    # Configuration\n",
    "    reference_width_cm, reference_height_cm = 4.0, 2.1\n",
    "    marker_id, marker_size_cm = 0, 5.1\n",
    "    soft_mode = True\n",
    "    last_cm_per_pixel = None\n",
    "    marker_status = \"No marker detected\"\n",
    "\n",
    "    aruco_detector = setup_aruco_detector()\n",
    "    csv_filename = init_csv_logger()\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_idx += 1\n",
    "        vis = frame.copy()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # --- Detect ArUco marker ---\n",
    "        cm_per_pixel, measured_marker_cm, marker_corners = detect_aruco_scale(\n",
    "            gray, aruco_detector, marker_id, marker_size_cm\n",
    "        )\n",
    "\n",
    "        if marker_corners is not None:\n",
    "            int_box = np.intp(marker_corners)\n",
    "            cv2.polylines(vis, [int_box], True, (255, 0, 0), 2)\n",
    "            cv2.putText(vis, f\"Scale: {cm_per_pixel:.6f} cm/px\", (10, 25),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 0), 2)\n",
    "            last_cm_per_pixel = cm_per_pixel\n",
    "            marker_status = f\"Marker OK (ID {marker_id})\"\n",
    "        else:\n",
    "            if last_cm_per_pixel is not None and soft_mode:\n",
    "                cm_per_pixel = last_cm_per_pixel\n",
    "                marker_status = f\"Marker lost - using last scale = {last_cm_per_pixel:.6f} cm/px\"\n",
    "            else:\n",
    "                marker_status = \"No marker - using reference tin size\"\n",
    "                h_img, w_img = gray.shape\n",
    "                cm_per_pixel_x = reference_width_cm / w_img\n",
    "                cm_per_pixel_y = reference_height_cm / h_img\n",
    "                cm_per_pixel = (cm_per_pixel_x + cm_per_pixel_y) / 2\n",
    "\n",
    "        # --- Object detection ---\n",
    "        gray2 = preprocess_image(frame)\n",
    "        largest_contour = detect_largest_contour(gray2)\n",
    "\n",
    "        if largest_contour is not None:\n",
    "            result = compute_volume_and_error(largest_contour, cm_per_pixel)\n",
    "            if result:\n",
    "                w_cm, h_cm, volume_cm3, err_total, (x, y, w, h) = result\n",
    "\n",
    "                cv2.rectangle(vis, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(vis, f\"Width: {w_cm:.2f} cm  Height: {h_cm:.2f} cm\", (x, y - 25),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                cv2.putText(vis, f\"Vol: {volume_cm3:.1f} cm^3 (+/- {err_total:.1f}%)\",\n",
    "                            (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "                log_measurement(csv_filename, frame_idx, marker_status, cm_per_pixel, w_cm, h_cm, volume_cm3, err_total)\n",
    "\n",
    "        cv2.putText(vis, marker_status, (10, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 200, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Object Volume Measurement (Modular)\", vis)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\nâœ… Data saved to: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Data saved to: object_measurements_2025-11-13_19-52-19.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_measurement(use_webcam=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
